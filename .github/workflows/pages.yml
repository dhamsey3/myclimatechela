name: Build & Deploy (static + Medium)

on:
  push:
    branches: [main, master]
  schedule:
    - cron: "0 */6 * * *"
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: pages
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.x"

      - name: Install deps
        run: |
          set -e
          python -m pip install --upgrade pip
          pip install feedparser requests Pillow

      - name: Generate posts.json from Medium RSS
        run: |
          set -e
          python - <<'PY'
          import re, html, textwrap, time, datetime, json, pathlib, sys
          import feedparser, requests

          FEED = "https://medium.com/feed/@myclimatedefinition"
          out = pathlib.Path("public/posts.json")
          out.parent.mkdir(parents=True, exist_ok=True)

          def clean(s): return html.unescape(re.sub("<.*?>","", s or ""))
          def to_iso(ts):
              if not ts: return ""
              try:
                  return datetime.datetime.fromtimestamp(time.mktime(ts), datetime.timezone.utc).isoformat()
              except Exception:
                  return ""

          def extract_image(entry):
              if entry.get("media_thumbnail"):
                  u = entry["media_thumbnail"][0].get("url")
                  if u: return u
              if entry.get("media_content"):
                  u = entry["media_content"][0].get("url")
                  if u: return u
              blob = entry.get("summary","")
              for c in entry.get("content", []):
                  blob += " " + c.get("value","")
              m = re.search(r'<img[^>]+src=["\']([^"\']+)["\']', blob, re.I)
              return m.group(1) if m else None

          headers = {"User-Agent": "Mozilla/5.0"}
          items = []
          try:
              r = requests.get(FEED, headers=headers, timeout=30)
              r.raise_for_status()
              feed = feedparser.parse(r.content)
              for e in getattr(feed, "entries", []):
                  items.append({
                      "title": e.get("title","Untitled"),
                      "permalink": e.get("link","#"),
                      "external_url": e.get("link","#"),
                      "date": to_iso(e.get("published_parsed")),
                      "summary": textwrap.shorten(clean(e.get("summary","")), 220),
                      "image": extract_image(e),
                  })
          except Exception as e:
              print(f"ERROR fetching feed: {e}", file=sys.stderr)

          out.write_text(json.dumps(items, ensure_ascii=False), encoding="utf-8")
          print(f"Wrote {len(items)} posts to {out}")
          PY

      - name: Ensure head tags (SEO/OG/icons/manifest)
        run: |
          set -e
          python - <<'PY'
          from pathlib import Path
          p = Path("public/index.html")
          html = p.read_text(encoding="utf-8")

          snippet = '''\
  <meta name="description" content="Stories, definitions, and experiments in sustainability — auto-synced from Medium.">
  <link rel="canonical" href="https://myclimatedefinition.org/">
  <meta property="og:type" content="website">
  <meta property="og:title" content="My Climate Definition">
  <meta property="og:description" content="Stories, definitions, and experiments in sustainability — auto-synced from Medium.">
  <meta property="og:url" content="https://myclimatedefinition.org/">
  <meta property="og:image" content="https://myclimatedefinition.org/img/og.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="My Climate Definition">
  <meta name="twitter:description" content="Stories, definitions, and experiments in sustainability — auto-synced from Medium.">
  <meta name="twitter:image" content="https://myclimatedefinition.org/img/og.png">
  <link rel="icon" href="/img/favicon.ico" sizes="any">
  <link rel="icon" type="image/png" href="/img/favicon-32.png" sizes="32x32">
  <link rel="icon" type="image/png" href="/img/favicon-16.png" sizes="16x16">
  <link rel="apple-touch-icon" href="/img/apple-touch-icon.png">
  <link rel="manifest" href="/manifest.webmanifest">
  <meta name="theme-color" content="#0f172a">'''

          markers = ["og:image", "manifest.webmanifest", "apple-touch-icon", "favicon.ico"]
          if not any(m in html for m in markers):
              if "</head>" in html:
                  html = html.replace("</head>", snippet + "\n</head>")
                  p.write_text(html, encoding="utf-8")
                  print("Injected head tags.")
              else:
                  print("No </head> tag found; skipped injection.")
          else:
              print("Head tags already present; no changes.")
          PY

      - name: Generate icons & social image from logo.png
        run: |
          set -e
          python - <<'PY'
          from PIL import Image, ImageColor, ImageDraw
          import pathlib, sys
          base = pathlib.Path("public"); imgd = base/"img"; imgd.mkdir(parents=True, exist_ok=True)
          logo = imgd/"logo.png"
          if not logo.exists():
              print("No public/img/logo.png found; skipping icon generation."); sys.exit(0)

          THEME_BG = "#0f172a"
          ICON_SIZES = [192, 512]
          APPLE_SIZE = 180
          OG_W, OG_H = 1200, 630

          src = Image.open(logo).convert("RGBA")

          def on_canvas(w,h,scale=0.66, bg=THEME_BG):
              c = Image.new("RGBA",(w,h), ImageColor.getrgb(bg)+(255,))
              r = src.copy()
              target = int(min(w,h)*scale)
              ratio = src.width/src.height
              tw = int(target*ratio); th = target
              if tw > int(w*scale):
                  tw = int(w*scale); th = int(tw/ratio)
              r.thumbnail((tw,th), Image.LANCZOS)
              c.alpha_composite(r, ((w-r.width)//2, (h-r.height)//2))
              return c

          for s in ICON_SIZES:
              on_canvas(s,s).save(imgd/f"icon-{s}.png")
          on_canvas(APPLE_SIZE,APPLE_SIZE).convert("RGB").save(imgd/"apple-touch-icon.png")

          base512 = on_canvas(512,512)
          base512.save(imgd/"favicon-512.png")
          base512.resize((32,32), Image.LANCZOS).save(imgd/"favicon-32.png")
          base512.resize((16,16), Image.LANCZOS).save(imgd/"favicon-16.png")
          base512.save(imgd/"favicon.ico", sizes=[(16,16),(32,32),(48,48),(64,64)])

          og = on_canvas(OG_W, OG_H, scale=0.45)
          d = ImageDraw.Draw(og)
          caption = "My Climate Definition"
          bbox = d.textbbox((0,0), caption)
          tw = bbox[2]-bbox[0]
          d.text(((OG_W - tw)//2, OG_H - 60), caption, fill=(255,255,255,230))
          og.convert("RGB").save(imgd/"og.png", quality=92)

          print("Generated: icon-192.png, icon-512.png, apple-touch-icon.png, favicon.{ico,16,32}, og.png")
          PY

      - name: Create manifest.webmanifest if missing
        run: |
          set -e
          python - <<'PY'
          from pathlib import Path
          m = Path("public/manifest.webmanifest")
          if not m.exists():
              m.write_text('''{
  "name": "My Climate Definition",
  "short_name": "ClimateDef",
  "start_url": "/",
  "display": "standalone",
  "background_color": "#ffffff",
  "theme_color": "#0f172a",
  "icons": [
    { "src": "/img/icon-192.png", "sizes": "192x192", "type": "image/png" },
    { "src": "/img/icon-512.png", "sizes": "512x512", "type": "image/png" }
  ]
}''', encoding="utf-8")
              print("Wrote manifest.webmanifest")
          else:
              print("manifest.webmanifest already exists")
          PY

      - name: Generate sitemap.xml and robots.txt
        run: |
          set -e
          python - <<'PY'
          import json, pathlib, datetime
          base = "https://myclimatedefinition.org"
          pub = pathlib.Path("public")
          posts = []
          try:
              posts = json.loads(pub.joinpath("posts.json").read_text("utf-8"))
          except Exception:
              pass
          urls = [f"{base}/"]
          for p in posts:
              u = p.get("permalink") or p.get("external_url")
              if u and u.startswith("http"): urls.append(u)
          now = datetime.date.today().isoformat()
          lines = ['<?xml version="1.0" encoding="UTF-8"?>','<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">']
          for u in sorted(set(urls)):
              lines += ["<url>", f"<loc>{u}</loc>", f"<lastmod>{now}</lastmod>", "</url>"]
          lines += ["</urlset>"]
          pub.joinpath("sitemap.xml").write_text("\n".join(lines), "utf-8")
          pub.joinpath("robots.txt").write_text("User-agent: *\nAllow: /\nSitemap: "+base+"/sitemap.xml\n","utf-8")
          PY

      - name: Verify files
        run: |
          set -e
          test -f public/index.html
          test -f public/css/style.css
          test -f public/js/main.js
          test -f public/posts.json

      - name: Debug listing
        run: |
          echo "=== index.html (first 80 lines) ==="
          awk 'NR<=80{printf "%03d| %s\n", NR, $0}' public/index.html
          echo "=== img dir ==="
          ls -al public/img || true
          echo "=== manifest.webmanifest ==="
          [ -f public/manifest.webmanifest ] && cat public/manifest.webmanifest || echo "manifest.webmanifest not found"

      - name: Add CNAME
        run: echo 'www.climatedefinition.org' > public/CNAME

      - name: Configure Pages
        uses: actions/configure-pages@v5

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy
        id: deployment
        uses: actions/deploy-pages@v4
