name: "Build and Deploy (static + Medium)"

on:
  push:
    branches:
      - main
      - master
  schedule:
    - cron: "0 */6 * * *"
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: pages
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.x"
          cache: pip
          cache-dependency-path: requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Generate posts.json from Medium RSS
        shell: bash
        run: |
          python - <<'PY'
          import re, html, textwrap, time, datetime, json, pathlib, sys
          import feedparser, requests

          FEED = "https://medium.com/feed/@myclimatedefinition"
          out = pathlib.Path("public/posts.json")
          out.parent.mkdir(parents=True, exist_ok=True)

          def clean(s): 
              return html.unescape(re.sub("<.*?>","", s or ""))

          def to_iso(ts):
              if not ts: 
                  return ""
              try:
                  return datetime.datetime.fromtimestamp(time.mktime(ts), datetime.timezone.utc).isoformat()
              except Exception:
                  return ""

          def extract_image(entry):
              if entry.get("media_thumbnail"):
                  u = entry["media_thumbnail"][0].get("url")
                  if u: return u
              if entry.get("media_content"):
                  u = entry["media_content"][0].get("url")
                  if u: return u
              blob = entry.get("summary","")
              for c in entry.get("content", []):
                  blob += " " + c.get("value","")
              m = re.search(r'<img[^>]+src=["\']([^"\']+)["\']', blob, re.I)
              return m.group(1) if m else None

          headers = {"User-Agent": "Mozilla/5.0"}
          items = []
          try:
              r = requests.get(FEED, headers=headers, timeout=30)
              r.raise_for_status()
              feed = feedparser.parse(r.content)
              for e in getattr(feed, "entries", []):
                  items.append({
                      "title": e.get("title","Untitled"),
                      "permalink": e.get("link","#"),
                      "external_url": e.get("link","#"),
                      "date": to_iso(e.get("published_parsed")),
                      "summary": textwrap.shorten(clean(e.get("summary","")), 220),
                      "image": extract_image(e),
                  })
          except Exception as e:
              print(f"ERROR fetching feed: {e}", file=sys.stderr)

          out.write_text(json.dumps(items, ensure_ascii=False), encoding="utf-8")
          print(f"Wrote {len(items)} posts to {out}")
          PY

      - name: Disable Jekyll
        run: touch public/.nojekyll

      - name: Verify required files exist
        run: |
          set -e
          test -f public/index.html
          test -f public/css/style.css
          test -f public/js/main.js
          test -f public/posts.json

      - name: Verify images exist
        run: |
          set -e
          test -f public/img/logo.png
          [ -f public/img/logo@2x.png ] || echo "Note: public/img/logo@2x.png not found (optional for retina)."

      - name: Add CNAME (apex domain)
        run: |
          mkdir -p public
          echo 'myclimatedefinition.org' > public/CNAME

      - name: Configure Pages
        uses: actions/configure-pages@v5

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: public
      - name: Generate icons & social image from logo.png
        run: |
          python - <<'PY'
          from PIL import Image, ImageOps, ImageColor, ImageDraw, ImageFont
          import pathlib, sys

          base_dir = pathlib.Path("public")
          img_dir  = base_dir / "img"
          logo_fp  = img_dir / "logo.png"

          if not logo_fp.exists():
              print("No public/img/logo.png found; skipping icon generation.")
              sys.exit(0)

          # Theme + sizes
          THEME_BG = "#0f172a"      # matches your header chip / theme-color
          ICON_SIZES = [192, 512]   # PWA icons
          APPLE_SIZE = 180          # Apple touch icon
          FAV_SIZES  = [(16,16),(32,32),(48,48),(64,64)]  # favicon.ico
          OG_SIZE    = (1200, 630)  # Social preview (Open Graph/Twitter)

          img_dir.mkdir(parents=True, exist_ok=True)
          logo = Image.open(logo_fp).convert("RGBA")

          def fit_on_canvas(canvas_w, canvas_h, scale=0.7, bg=THEME_BG):
              """Return a canvas with the logo centered, scaled to a % of min-dimension."""
              canvas = Image.new("RGBA", (canvas_w, canvas_h), ImageColor.getrgb(bg)+(255,))
              # compute target box
              target_h = int(min(canvas_w, canvas_h) * scale)
              # keep aspect ratio
              ratio = logo.width / logo.height
              target_w = int(target_h * ratio)
              # if too wide for canvas, clamp
              if target_w > int(canvas_w * scale):
                  target_w = int(canvas_w * scale)
                  target_h = int(target_w / ratio)
              resized = logo.copy()
              resized.thumbnail((target_w, target_h), Image.LANCZOS)
              x = (canvas_w - resized.width) // 2
              y = (canvas_h - resized.height) // 2
              canvas.alpha_composite(resized, (x, y))
              return canvas

          # 1) PWA icons
          for s in ICON_SIZES:
              out = fit_on_canvas(s, s, scale=0.66)
              out.convert("RGBA").save(img_dir / f"icon-{s}.png")

          # 2) Apple touch icon (no transparency preferred)
          apple = fit_on_canvas(APPLE_SIZE, APPLE_SIZE, scale=0.66).convert("RGB")
          apple.save(img_dir / "apple-touch-icon.png")

          # 3) Favicon PNGs + ICO
          fav_base = fit_on_canvas(512, 512, scale=0.66)  # high-res base
          fav_base.save(img_dir / "favicon-512.png")
          fav_32 = fav_base.resize((32,32), Image.LANCZOS)
          fav_16 = fav_base.resize((16,16), Image.LANCZOS)
          fav_32.save(img_dir / "favicon-32.png")
          fav_16.save(img_dir / "favicon-16.png")
          # multi-size ICO
          fav_base.save(img_dir / "favicon.ico", sizes=[(16,16),(32,32),(48,48),(64,64)])

          # 4) Open Graph image (1200x630)
          og = fit_on_canvas(OG_SIZE[0], OG_SIZE[1], scale=0.45)
          # optional: simple title at bottom (uses default PIL font)
          draw = ImageDraw.Draw(og)
          caption = "My Climate Definition"
          # simple centered caption
          w, h = draw.textlength(caption), 24
          draw.text(((OG_SIZE[0]-w)//2, OG_SIZE[1]-60), caption, fill=(255,255,255,230))
          og.convert("RGB").save(img_dir / "og.png", quality=92)

          print("Generated: icon-192.png, icon-512.png, apple-touch-icon.png, favicon-*.png, favicon.ico, og.png")
          PY
          
      - name: Generate sitemap.xml and robots.txt
        run: |
          python - <<'PY'
          import json, pathlib, datetime
          base = "https://myclimatedefinition.org"
          pub = pathlib.Path("public")
          posts = []
          try:
              posts = json.loads(pub.joinpath("posts.json").read_text("utf-8"))
          except Exception:
              pass
          urls = [f"{base}/"]
          for p in posts:
              u = p.get("permalink") or p.get("external_url")
              if u and u.startswith("http"): urls.append(u)
          now = datetime.date.today().isoformat()
          lines = ['<?xml version="1.0" encoding="UTF-8"?>',
                  '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">']
          for u in sorted(set(urls)):
              lines += [ "<url>", f"<loc>{u}</loc>", f"<lastmod>{now}</lastmod>", "</url>" ]
          lines += ["</urlset>"]
          pub.joinpath("sitemap.xml").write_text("\n".join(lines), "utf-8")
          pub.joinpath("robots.txt").write_text(
            "User-agent: *\nAllow: /\nSitemap: " + base + "/sitemap.xml\n", "utf-8"
          )
          PY



  deploy:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      pages: write
      id-token: write
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
